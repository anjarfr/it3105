# Environment parameters

board:
  size: 4
  shape: triangle #diamond

game:
  type: Peg #Hex
  open_cells: 1
  open_positions: [[2, 0]]

display:
  node_size: 1500
  initial_color: 'white'
  filled_color: 'plum'
  frequency: 0
  delay: 2
  display: # When should games be visualized?

# Agent parameters

RL_system:
  episodes: 10000

critic:
  type: table #NN
  dimensions: [15, 20, 30, 5, 1] # Number of nodes in each layer
  learning_rate: 0.1 # If NN is used, lr for critic should be much lower than for actor
  eligibility_decay: 0.5 # Range [0,1]
  discount_factor: 0.9 # Range [0,1]

actor:
  learning_rate: 0.5
  eligibility_decay: 0.6 # Range [0,1]
  discount_factor: 0.9 # Range [0,1]
  init_epsilon: 0.2
  epsilon_decay_rate: 0.6
